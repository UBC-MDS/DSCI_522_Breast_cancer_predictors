{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORT   \n",
    "# Breast Cancer Malignancy Classifier based on Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Introduction  \n",
    "This report is meant to guide you through our anlysis process, findings and the final model of the Decision Tree  \n",
    "\n",
    "The primary question of research was whether we would be able to build and train a Decision Tree classifier based on the sample data that can predict the malignancy of the cancer, with a reasonable level of accuracy, when faced with new data.\n",
    "***\n",
    "\n",
    "## Exploratory Data Analysis  \n",
    "During the exporatory data analysis we tried to investigate the different features and gain an intuition of their predicitive power. Each feature had 3 levels of measurement; i.e. mean, standard error, and worst(outliers). To avoid the redundancies in the data, we decided to focus on the fatures measured as means for the analysis.  \n",
    "\n",
    "To gauge the predicitive strength of the feautres, we wanted to look at the distribution of each variable while segregating them by diagnosis. We were looking for features that showcased distributions with distance between there centers or a low entropy in their distribution to act as strong predictors if malignancy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imgs/feature_histograms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are a significant number of features that would serve as strong predictors based on the centers of there distributions.  Some of the features also have a signifianct skew in the distributions. Exploring whether some of these fatures have outliers at the end of their tails is something that could be revisited when trying to improve the accuracy of our Decision Tree model. If on exploring the outliers we do find out that they are mistakesoe data entry errors, we could remove them to improve our model's accuracy\n",
    "\n",
    "Some expected strong predictors could be:\n",
    "* radius_mean  \n",
    "* perimeter_mean\n",
    "* concave_points_mean  \n",
    "* concavity_mean \n",
    "* texture_mean   \n",
    "\n",
    "To further explore some of these features we tried to plot the distribution as box plots to see difference between the percentile values of the two categories.\n",
    "\n",
    "![](../imgs/box_plots.png)\n",
    "\n",
    "These plots do reinforce my belief that these features should be good predictors. Not only is the spread of values for the malignant diagnosis larger, but in most cases 80% of the benign values for a feature lie below the 25 percentile mark of the resepective malignant feature. This to me suggests that malignant tumors seem to have larger values for the features in display above.\n",
    "\n",
    "The plots also suggest that there are outliers and some cases they are quite far. However, for now we do not have any information that would help us reject these outliers and hence we must assume that these values are possible.\n",
    "***\n",
    "\n",
    "## Hyperparameter Optimization\n",
    "Now that we have a good understanding of predicitive strength of the features and which ones will most likely be selected by the decisin tree, our next was to pick optimal values for the hyperparameters of our model.  \n",
    "\n",
    "The decision tree has two hyperparameters that we tried to optimize for; max_depth and min_sample_split. To pick the optimal value for both, we repeatedly trained the model and varied the values for the two hyperparameters and recorded the respective training and test accuracy for the same.  \n",
    "\n",
    "After repeating the experiment multiple times, it appears that the highest test accuracy we've been able to achieve is 93.85% while at a max depth of 5.\n",
    "\n",
    "From the plot below, it is also clear that the behavior of the decision tree is rather eratic, and may be we can try to adjust the min_sample_split for depth 5 to see if we can improve the test accuracy while also creating a more stable model.\n",
    "\n",
    "#### Optimum Hyperparameter | max_depth = 5¶\n",
    "\n",
    "![](../imgs/max_depth_graph.png)\n",
    "\n",
    "Considering that the min_sample_split doesn't restrict the maximum number of sample splits, I would default to a smaller value of min_sample_split to allow the model more freedom to pick the best or optimal split size. The plot shows that the accuracy drops as the min_sample_split rises, which is expected. Hence I would pick a value of 2 for the min_sample_split.\n",
    "\n",
    "#### Optimum Hyperparameter | min_sample_split = 2¶\n",
    "\n",
    "![](../imgs/min_sample_split_graph.png)\n",
    "***\n",
    "\n",
    "# Final Decision Tree Model  \n",
    "Using the values for the Hyperparameters (max_depth = 5, min_sample_split = 2), we now retrained the model one final time, and recorded a training accuracy 98.42%. This model is now ready to accept new data to predict malignancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imgs/breast_cancer_malignancy_tree.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
